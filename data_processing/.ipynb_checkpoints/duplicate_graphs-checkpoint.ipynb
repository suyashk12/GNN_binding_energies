{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    with open(filename, \"r\") as file_handle:\n",
    "        string_dict = json.load(file_handle)\n",
    "    return _load_data_from_string_dict(string_dict)\n",
    "\n",
    "def _load_data_from_string_dict(string_dict):\n",
    "    result_dict = {}\n",
    "    for key in string_dict:\n",
    "        data = copy.deepcopy(string_dict[key])\n",
    "        if 'edges' in data:\n",
    "            data[\"links\"] = data.pop(\"edges\")\n",
    "        graph = nx.node_link_graph(data)\n",
    "        result_dict[key] = graph\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of SMILES and values are graphs\n",
    "loaddir = \"../data/graphs/\"\n",
    "train_data = load_data_from_file(loaddir+\"cleaned_graph_data_10June.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_graphs = [] # list of graphs along with duplicates\n",
    "training_graph_names = [] # list of names of graphs\n",
    "\n",
    "for i in range(len(train_data)): # for each graph in the training set\n",
    "    \n",
    "    mol = list(train_data.keys())[i]\n",
    "    graph = train_data[mol] # we want to fully connect all target nodes in this graph so message passing works\n",
    "    \n",
    "    # add NONE bonds to all target nodes\n",
    "    all_graphs = []\n",
    "    all_names = []\n",
    "    \n",
    "    count = 0\n",
    "    for n_i in graph.nodes: # for each node in the graph\n",
    "        \n",
    "        graph_i = graph.copy()\n",
    "        \n",
    "        for nb_i in nx.non_neighbors(graph_i, n_i): # get all neighbors for target node\n",
    "            graph_i.add_edge(n_i, nb_i, bond_type='NONE') # add edge to target node\n",
    "            \n",
    "        for j in range(len(graph_i.nodes[n_i]['orbitals'])): # For each orbital specified for the target node\n",
    "            \n",
    "            graph_ij = graph_i.copy()\n",
    "            \n",
    "            if str(graph_ij.nodes[n_i]['orbitals'][j]) != '-1': # If the orbital has a specified binding energy\n",
    "                \n",
    "                graph_ij.nodes[n_i]['orbitals'] = [graph_ij.nodes[n_i]['orbitals'][j]]\n",
    "                graph_ij.nodes[n_i]['binding_energies'] = [graph_ij.nodes[n_i]['binding_energies'][j]]\n",
    "                graph_ij.nodes[n_i]['e_neg_score'] = [graph_ij.nodes[n_i]['e_neg_score'][0]] # Only depends on atom\n",
    " \n",
    "                # Specify this node as the prediction target\n",
    "                graph_ij.nodes[n_i]['pred'] = True \n",
    "\n",
    "                for n in graph_ij.nodes:\n",
    "                    if n != n_i:\n",
    "                        graph_ij.nodes[n]['pred'] = False\n",
    "                all_graphs.append(graph_ij) # add graph to list of graphs\n",
    "\n",
    "                name = f\"{mol}_{n_i}_{j}\" # SMILES + index of target node + index of orbital\n",
    "\n",
    "                all_names.append(name)\n",
    "                count += 1\n",
    "        \n",
    "    training_graphs = training_graphs + all_graphs # add all graphs to the list of graphs\n",
    "    training_graph_names = training_graph_names + all_names # add all names to the list of names\n",
    "    #print(f\"Graph {i} with {len(all_graphs)} graphs added to training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dict = dict(zip(training_graph_names, training_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_json_file(graph_dict, filename, **kwargs):\n",
    "    with open(filename, \"w\") as file_handle:\n",
    "        json_string = json.dumps(graph_dict, default=nx.node_link_data, **kwargs)\n",
    "        file_handle.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data_to_json_file(training_data_dict, loaddir+\"graph_data_duplicates.json\", indent=2) # write the training data to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
