{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca29ad0-47cd-48f8-a9a1-9ad26e147c74",
   "metadata": {},
   "source": [
    "This jupyter notebook teaches you how to create a static (i.e. untrained) state reduction object and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ba5bee-d0c0-44e7-a924-2c7c0d12724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.insert(0,str(root_dir))\n",
    "\n",
    "from Gyms.SimulatedNetwork import SimulatedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba9eaf2-d54f-4353-b088-4ccf78384cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the state reduction function\n",
    "from StateReduction.StaticStateSimple import StaticStateSimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a528d5-af3f-4c5b-9bef-0fe0022a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of state and action spaces\n",
    "state_dim  = 4 # Dimension of reduced state space\n",
    "action_dim = 5 # Number of stimuli in action space (each stimulus needs a value of {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110da036-7fd6-427a-b839-c8f4ed6e8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object of the state reduction function\n",
    "state = StaticStateSimple(state_dim=state_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5373dba-d31c-4f31-9906-6db506053bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [0. 0. 0. 0.], Reward: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and initialize it\n",
    "env      = SimulatedNetwork(action_dim=action_dim,\n",
    "                            state_dim=state_dim,\n",
    "                            state_object=state) # Use the state object\n",
    "state, _ = env.reset()\n",
    "env.render() # This function gives you the current state + reward, which both is 0 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc3ef6a-fb75-4834-b6e0-97826997584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can now for example get a random action:\n",
    "action = env.action_space.sample()\n",
    "action\n",
    "# This action can then be applied to the environment with:\n",
    "# state, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a4cc22-d672-490f-93c6-d98b3ca82de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulate with action: [3 0 0 1 4]\n",
      "Reward: -1, Avg. reward: -1.0\n",
      "State: [ 0.         -0.37831993  0.44328246  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 4 1 1]\n",
      "Reward: 2, Avg. reward: 0.5\n",
      "State: [ 0.         -0.39862488 -0.43131245  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 4 2 1]\n",
      "Reward: 2, Avg. reward: 1.0\n",
      "State: [-1.         -0.42788421 -0.1966701   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 1 3 4]\n",
      "Reward: -1, Avg. reward: 0.5\n",
      "State: [-0.5         0.         -0.27513092  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 1 0 3]\n",
      "Reward: 4, Avg. reward: 1.2\n",
      "State: [ 0.         -0.31371759 -0.4349646   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 0 0 4]\n",
      "Reward: 2, Avg. reward: 1.3333333333333333\n",
      "State: [ 0.         -0.37158869  0.545357    0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 1 1 0]\n",
      "Reward: 2, Avg. reward: 1.4285714285714286\n",
      "State: [ 0.         -0.43106645 -0.09443329  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 2 3 2]\n",
      "Reward: 2, Avg. reward: 1.5\n",
      "State: [0.         0.40913031 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 1 4 1]\n",
      "Reward: 1, Avg. reward: 1.4444444444444444\n",
      "State: [ 0.5         0.33019174 -0.42780597  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2 2 3 3]\n",
      "Reward: 2, Avg. reward: 1.5\n",
      "State: [-0.5  0.   0.   0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1 1 1 2]\n",
      "Reward: 2, Avg. reward: 1.5454545454545454\n",
      "State: [ 0.5        -0.37358965  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1 4 0 4]\n",
      "Reward: 2, Avg. reward: 1.5833333333333333\n",
      "State: [-1.  0.  0.  0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 1 1 4]\n",
      "Reward: 2, Avg. reward: 1.6153846153846154\n",
      "State: [ 0.5        -0.46959478  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 4 1 3]\n",
      "Reward: 5, Avg. reward: 1.8571428571428572\n",
      "State: [-0.5        -0.35335332 -0.19023405  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2 1 3 3]\n",
      "Reward: 0, Avg. reward: 1.7333333333333334\n",
      "State: [0.5        0.         0.37624617 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2 0 1 3]\n",
      "Reward: 0, Avg. reward: 1.625\n",
      "State: [-1.        -0.4341051  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4 2 0 4]\n",
      "Reward: 5, Avg. reward: 1.8235294117647058\n",
      "State: [-0.5        0.        -0.3624221  0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1 1 1 2]\n",
      "Reward: 1, Avg. reward: 1.7777777777777777\n",
      "State: [-1.         -0.23131655  0.31068691  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 1 2 3]\n",
      "Reward: 3, Avg. reward: 1.8421052631578947\n",
      "State: [ 0.5        -0.4854325   0.12631953  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 2 1 1]\n",
      "Reward: 1, Avg. reward: 1.8\n",
      "State: [0.         0.         0.30853839 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 1 4 3]\n",
      "Reward: 2, Avg. reward: 1.8095238095238095\n",
      "State: [0.         0.16517156 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 1 1 1]\n",
      "Reward: -1, Avg. reward: 1.6818181818181819\n",
      "State: [-1.         -0.46713646  0.27977946  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 2 3 4]\n",
      "Reward: 4, Avg. reward: 1.7826086956521738\n",
      "State: [ 0.          0.         -0.37505423  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 4 2 1]\n",
      "Reward: 3, Avg. reward: 1.8333333333333333\n",
      "State: [ 0.5        -0.09896092 -0.32466186  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2 4 1 1]\n",
      "Reward: 0, Avg. reward: 1.76\n",
      "State: [-0.5         0.          0.29993459  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 0 2 1]\n",
      "Reward: 2, Avg. reward: 1.7692307692307692\n",
      "State: [ 0.         -0.41752465  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 2 1 4]\n",
      "Reward: 1, Avg. reward: 1.7407407407407407\n",
      "State: [ 0.         -0.30416956 -0.21003453  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 0 1 0]\n",
      "Reward: 2, Avg. reward: 1.75\n",
      "State: [-0.5        -0.28110244  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4 0 1 4]\n",
      "Reward: 2, Avg. reward: 1.7586206896551724\n",
      "State: [ 0.         -0.32568753  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 2 0 0]\n",
      "Reward: 0, Avg. reward: 1.7\n",
      "State: [-0.5        -0.26826301 -0.3245967   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4 1 3 2]\n",
      "Reward: 1, Avg. reward: 1.6774193548387097\n",
      "State: [ 0.         -0.26682417  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2 4 3 2]\n",
      "Reward: -2, Avg. reward: 1.5625\n",
      "State: [ 0.5        -0.44105734 -0.18288638  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2 2 0 2]\n",
      "Reward: -1, Avg. reward: 1.4848484848484849\n",
      "State: [0.5        0.         0.25586435 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3 1 0 2]\n",
      "Reward: 3, Avg. reward: 1.5294117647058822\n",
      "State: [0.5        0.         0.15558387 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 2 1 0]\n",
      "Reward: 0, Avg. reward: 1.4857142857142858\n",
      "State: [-1.          0.41148643  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0 2 0 0]\n",
      "Reward: 0, Avg. reward: 1.4444444444444444\n",
      "State: [-0.5        -0.42471539  0.34842983  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 0 3 1]\n",
      "Reward: 1, Avg. reward: 1.4324324324324325\n",
      "State: [-0.5         0.33736985  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 1 1 3]\n",
      "Reward: 3, Avg. reward: 1.4736842105263157\n",
      "State: [-0.5        0.6250964  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 0 3 2]\n",
      "Reward: 0, Avg. reward: 1.435897435897436\n",
      "State: [-0.5        -0.43741045 -0.05489038  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 3 3 0]\n",
      "Reward: 0, Avg. reward: 1.4\n",
      "State: [ 0.         -0.37263007  0.22740283  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2 0 0 2]\n",
      "Reward: 2, Avg. reward: 1.4146341463414633\n",
      "State: [-0.5         0.         -0.19137389  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 0 0 4]\n",
      "Reward: -1, Avg. reward: 1.3571428571428572\n",
      "State: [-0.5        0.         0.3304419  0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 2 0 4]\n",
      "Reward: -2, Avg. reward: 1.2790697674418605\n",
      "State: [-0.5        -0.24320593 -0.24225521  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 0 2 1]\n",
      "Reward: 4, Avg. reward: 1.3409090909090908\n",
      "State: [ 0.5         0.         -0.22964579  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3 3 3 4]\n",
      "Reward: 2, Avg. reward: 1.3555555555555556\n",
      "State: [-0.5        -0.39646717  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3 0 0 1]\n",
      "Reward: 2, Avg. reward: 1.3695652173913044\n",
      "State: [ 0.          0.         -0.25435088  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 2 0 2]\n",
      "Reward: -1, Avg. reward: 1.3191489361702127\n",
      "State: [-1.        -0.2191472  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 4 1 3]\n",
      "Reward: 5, Avg. reward: 1.3958333333333333\n",
      "State: [-0.5        -0.38906127 -0.11960042  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3 0 2 3]\n",
      "Reward: 1, Avg. reward: 1.3877551020408163\n",
      "State: [-1.          0.          0.22309226  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1 3 3 2]\n",
      "Reward: 4, Avg. reward: 1.44\n",
      "State: [ 0.5        -0.37909398  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2 3 4 3]\n",
      "Reward: 3, Avg. reward: 1.4705882352941178\n",
      "State: [ 0.          0.         -0.23905647  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4 2 1 1]\n",
      "Reward: -1, Avg. reward: 1.4230769230769231\n",
      "State: [ 0.5        -0.42238432 -0.2112149   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 1 3 4]\n",
      "Reward: 0, Avg. reward: 1.3962264150943395\n",
      "State: [-0.5        -0.30070286  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 2 4 3]\n",
      "Reward: -4, Avg. reward: 1.2962962962962963\n",
      "State: [-1.          0.23885544  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 0 0 1]\n",
      "Reward: 3, Avg. reward: 1.3272727272727274\n",
      "State: [ 0.5        0.531307  -0.3842956  0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1 3 4 3]\n",
      "Reward: 1, Avg. reward: 1.3214285714285714\n",
      "State: [-1.          0.          0.16940106  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2 2 2 0]\n",
      "Reward: 1, Avg. reward: 1.3157894736842106\n",
      "State: [-0.5         0.         -0.16888959  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4 4 4 3]\n",
      "Reward: 2, Avg. reward: 1.3275862068965518\n",
      "State: [ 0.5        0.        -0.0779777  0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 4 2 4]\n",
      "Reward: 2, Avg. reward: 1.3389830508474576\n",
      "State: [0.5        0.33920029 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0 0 0 2]\n",
      "Reward: 1, Avg. reward: 1.3333333333333333\n",
      "State: [ 0.5        0.        -0.1588214  0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 1 0 1]\n",
      "Reward: -2, Avg. reward: 1.278688524590164\n",
      "State: [-1.          0.37510068  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0 1 0 0]\n",
      "Reward: 2, Avg. reward: 1.2903225806451613\n",
      "State: [ 0.         -0.41104196 -0.32642602  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3 4 3 3]\n",
      "Reward: -2, Avg. reward: 1.2380952380952381\n",
      "State: [ 0.         -0.43914445  0.03275424  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 3 1 0]\n",
      "Reward: -1, Avg. reward: 1.203125\n",
      "State: [-0.5        -0.27308637 -0.44081462  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 3 3 1]\n",
      "Reward: 1, Avg. reward: 1.2\n",
      "State: [0.         0.         0.22374944 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 1 4 2]\n",
      "Reward: 0, Avg. reward: 1.1818181818181819\n",
      "State: [0.         0.11405551 0.27431854 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 1 4 3]\n",
      "Reward: -7, Avg. reward: 1.0597014925373134\n",
      "State: [0.         0.         0.15866906 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1 4 4 0]\n",
      "Reward: -2, Avg. reward: 1.0147058823529411\n",
      "State: [ 0.5        -0.31536909  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3 0 2 0]\n",
      "Reward: 3, Avg. reward: 1.0434782608695652\n",
      "State: [ 0.5        -0.33910074  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4 4 0 3]\n",
      "Reward: 2, Avg. reward: 1.0571428571428572\n",
      "State: [0.5 0.  0.  0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 2 2 0]\n",
      "Reward: 1, Avg. reward: 1.056338028169014\n",
      "State: [-1.         -0.46885108 -0.18207967  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 3 0 3]\n",
      "Reward: -3, Avg. reward: 1.0\n",
      "State: [0.         0.         0.12404626 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 2 4 4]\n",
      "Reward: 3, Avg. reward: 1.0273972602739727\n",
      "State: [-0.5  0.   0.   0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4 1 1 4]\n",
      "Reward: 1, Avg. reward: 1.027027027027027\n",
      "State: [-1.         -0.39733659  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2 4 4 1]\n",
      "Reward: 0, Avg. reward: 1.0133333333333334\n",
      "State: [-0.5         0.          0.28472621  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1 4 4 2]\n",
      "Reward: 0, Avg. reward: 1.0\n",
      "State: [-1.          0.         -0.41577748  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3 4 4 2]\n",
      "Reward: 3, Avg. reward: 1.025974025974026\n",
      "State: [ 0.         -0.32672774  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3 0 0 0]\n",
      "Reward: 0, Avg. reward: 1.0128205128205128\n",
      "State: [ 0.         -0.38775591  0.1264291   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2 3 3 3]\n",
      "Reward: 0, Avg. reward: 1.0\n",
      "State: [0.         0.37204086 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 4 4 3]\n",
      "Reward: 2, Avg. reward: 1.0125\n",
      "State: [-1.         -0.32724791  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 2 3 3]\n",
      "Reward: 1, Avg. reward: 1.0123456790123457\n",
      "State: [0.         0.         0.05075264 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 3 0 1]\n",
      "Reward: 3, Avg. reward: 1.0365853658536586\n",
      "State: [-0.5         0.30297028  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2 1 2 0]\n",
      "Reward: 1, Avg. reward: 1.036144578313253\n",
      "State: [-0.5         0.         -0.17962864  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 2 2 3]\n",
      "Reward: 3, Avg. reward: 1.0595238095238095\n",
      "State: [ 0.5        -0.39691742 -0.43876429  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 0 4 2]\n",
      "Reward: 1, Avg. reward: 1.0588235294117647\n",
      "State: [-0.5  0.   0.   0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 4 0 4]\n",
      "Reward: 0, Avg. reward: 1.0465116279069768\n",
      "State: [-0.5         0.42211739  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 4 1 0]\n",
      "Reward: 2, Avg. reward: 1.0574712643678161\n",
      "State: [-0.5         0.          0.02770203  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1 2 2 2]\n",
      "Reward: 2, Avg. reward: 1.0681818181818181\n",
      "State: [ 0.5       -0.3801686  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 4 0 4]\n",
      "Reward: 0, Avg. reward: 1.0561797752808988\n",
      "State: [ 0.5        -0.34401747  0.39418619  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 0 2 1]\n",
      "Reward: 2, Avg. reward: 1.0666666666666667\n",
      "State: [0.         0.15708582 0.2770851  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1 1 1 0]\n",
      "Reward: -1, Avg. reward: 1.043956043956044\n",
      "State: [0.         0.         0.17310403 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2 1 2 1]\n",
      "Reward: -4, Avg. reward: 0.9891304347826086\n",
      "State: [0.5        0.         0.09745223 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1 3 1 4]\n",
      "Reward: 2, Avg. reward: 1.0\n",
      "State: [-1.          0.         -0.06683527  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2 0 4 2]\n",
      "Reward: 0, Avg. reward: 0.9893617021276596\n",
      "State: [-0.5        0.        -0.2523646  0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2 3 0 1]\n",
      "Reward: 3, Avg. reward: 1.0105263157894737\n",
      "State: [-0.5        -0.49809265  0.12303876  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0 3 2 3]\n",
      "Reward: -1, Avg. reward: 0.9895833333333334\n",
      "State: [ 0.5        -0.36652154  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1 0 1 1]\n",
      "Reward: 1, Avg. reward: 0.9896907216494846\n",
      "State: [-0.5         0.21779253  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4 1 4 3]\n",
      "Reward: 1, Avg. reward: 0.9897959183673469\n",
      "State: [ 0.5         0.06083461 -0.36595914  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0 3 1 4]\n",
      "Reward: 1, Avg. reward: 0.98989898989899\n",
      "State: [ 0.5        -0.22627366 -0.3156432   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4 2 1 1]\n",
      "Reward: 2, Avg. reward: 1.0\n",
      "State: [-0.5         0.          0.15443638  0.        ]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example code, that stimulates the network 100 times with a randomly sampled action, while calculating also the average reward received\n",
    "\n",
    "total_reward = 0\n",
    "action_count = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # For simplicity, choose a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Stimulate with action: {action}\")\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    action_count += 1\n",
    "\n",
    "    print(f\"Reward: {reward}, Avg. reward: {total_reward/action_count}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "    # If you want a more complete plotting of each step\n",
    "    # env.render()\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e01d04d-21a2-4760-9f81-7bfe2884a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average reward: {total_reward/action_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8fd05-d276-47a7-ab01-b2479859f09e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
